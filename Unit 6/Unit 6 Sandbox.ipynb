{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: Quiz 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Lists and Strings\n",
    "\n",
    "Suppose that you have a list of strings named examples. Write a Python loop that goes through the list and prints each string where the string length is three or more and the first and last characters of the strings are the same.\n",
    "\n",
    "Test your code on the following three versions of the list examples:\n",
    "examples = ['abab', 'xyz', 'aa', 'x', 'bcb']\n",
    "examples = ['', 'x', 'xy', 'xyx', 'xx']\n",
    "examples = ['aaa', 'be', 'abc', 'hello']\n",
    "\n",
    "You may do this exercise either in the interpreter or in a program. Please submit your code and the output from the three examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "examples = ['aaa', 'be', 'abc', 'hello']\n",
    "\n",
    "for example in examples:\n",
    "    stringlength = len(example) # length of the string\n",
    "    try:\n",
    "        firstchar = example[0] # \n",
    "        lastchar = example[stringlength-1]\n",
    "    \n",
    "        if stringlength >= 3 and firstchar == lastchar:\n",
    "            print(example)\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['abab', 'xyz', 'aa', 'x', 'bcb']\n",
    "\n",
    "stringlength = len(examples[0]) \n",
    "stringlength\n",
    "\n",
    "firstchar = examples[0][0]\n",
    "firstchar\n",
    "\n",
    "lastchar = examples[0][stringlength-1]\n",
    "lastchar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Reading and processing data in a file\n",
    "\n",
    "For this question, you are to write a program that reads the data in the file state_satscores_2004.txt. Each line of this file has name of a state, mean Verbal SAT score, and mean Math SAT score.\n",
    "\n",
    "After reading the data, \n",
    "a. Print the state with the highest mean Verbal SAT score \n",
    "b. Print each state that has a mean Math SAT score greater than 500\n",
    "\n",
    "Submit the code and the output from your program.\n",
    "\n",
    "You may use the code developed for the NBA data as a template, but it is absolutely essential that you use appropriate variable names and that you write original comments for what your program does.\n",
    "\n",
    "If you prefer, you can write this program with a csv reader, using state_satscores_2004.tsv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Verbal</th>\n",
       "      <th>Mean_Math</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>594</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean_Verbal  Mean_Math\n",
       "State                               \n",
       "South Dakota          594        597"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Courtesy of Pierre \n",
    "import pandas as pd\n",
    "\n",
    "scores = pd.read_csv('state_satscores_2004.tsv',sep=\"\\t\",header=None)\n",
    "\n",
    "scores.columns = ['State','Mean_Verbal','Mean_Math', 'delete']\n",
    "scores = scores.drop(columns='delete',axis=1)\n",
    "scores = scores.set_index('State')\n",
    "scores.sort_values(by='Mean_Verbal',ascending=False).head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Verbal</th>\n",
       "      <th>Mean_Math</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>497</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>515</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>518</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>501</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>522</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>505</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>501</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>503</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>515</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>499</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>511</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>516</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>501</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>487</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>527</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>518</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>528</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>501</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>507</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>523</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>537</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>538</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>554</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>540</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>524</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>567</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>554</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>559</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>551</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>563</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>585</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>587</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>560</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>584</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>564</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>587</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>569</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>569</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>587</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>565</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>569</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>593</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>594</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>562</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>582</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean_Verbal  Mean_Math\n",
       "State                                 \n",
       "New York                497        510\n",
       "Connecticut             515        515\n",
       "Massachusetts           518        523\n",
       "New Jersey              501        514\n",
       "New Hampshire           522        521\n",
       "Maine                   505        501\n",
       "Pennsylvania            501        502\n",
       "Rhode Island            503        502\n",
       "Virginia                515        509\n",
       "North Carolina          499        507\n",
       "Maryland                511        515\n",
       "Vermont                 516        512\n",
       "Indiana                 501        506\n",
       "Hawaii                  487        514\n",
       "Oregon                  527        528\n",
       "Alaska                  518        514\n",
       "Washington              528        531\n",
       "California              501        519\n",
       "Nevada                  507        514\n",
       "Arizona                 523        524\n",
       "Montana                 537        539\n",
       "Ohio                    538        542\n",
       "Colorado                554        553\n",
       "Idaho                   540        539\n",
       "West Virginia           524        514\n",
       "Tennessee               567        557\n",
       "New Mexico              554        543\n",
       "Kentucky                559        557\n",
       "Wyoming                 551        546\n",
       "Michigan                563        573\n",
       "Illinois                585        597\n",
       "Minnesota               587        593\n",
       "Alabama                 560        553\n",
       "Kansas                  584        585\n",
       "Louisiana               564        561\n",
       "Missouri                587        585\n",
       "Nebraska                569        576\n",
       "Oklahoma                569        566\n",
       "Wisconsin               587        596\n",
       "Utah                    565        556\n",
       "Arkansas                569        555\n",
       "Iowa                    593        602\n",
       "South Dakota            594        597\n",
       "Mississippi             562        547\n",
       "North Dakota            582        601"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "highMath = scores[scores['Mean_Math'] > 500]\n",
    "highMath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative solution (courtesy of Shawn Anderson)\n",
    "import os\n",
    "\n",
    "\n",
    "os.chdir('/Users/jason/Downloads')\n",
    "\n",
    "satfile = open ('state_satscores_2004.txt', 'r')\n",
    "# reset count for printing line numbers\n",
    "satlist = [ ]\n",
    "T500 = []\n",
    "for line in satfile:\n",
    "    textline = line.strip()\n",
    "    # split the line on whitespace\n",
    "    items = textline.split()\n",
    "    # add the list of items to the NBAlist\n",
    "    satlist.append(items)\n",
    "    #sort on the second element\n",
    "    satsort = sorted(satlist, key=lambda item:item[1])\n",
    "#print the last element - being the highest Verbal\n",
    "    if int(items[2]) >= int(500):\n",
    "        T500.append(items)#print(items)\n",
    "        #satlist[1][2])\n",
    "print(satsort[-1][0],'holds the highest Verbal SAT score,',satsort[-1][1],'/n')\n",
    "T500 = sorted(T500, key=lambda item:item[2])\n",
    "print('/n',T500)\n",
    "satfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: handling data in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Repeat the activity that we just went through in the lecture to read the data from the provided State Data. Transform the data.\n",
    "\n",
    "state_data = {'State':['Alabama','Alaska','Arizona','Arkansas'],'PostCode':['AL','AK','AZ','AR'],'Area':['52,423','656,424','*','53,182'],'Pop':['4,040,587','550,043','3,665,228','2,350,750']}\n",
    "\n",
    "Create a dataframe using pd.DataFrame(state_data, columns=['State','PostCode','Area','Pop'].\n",
    "\n",
    "Display the table.\n",
    "\n",
    "Index the table by 'State'.\n",
    "\n",
    "Replace the '*' with '0'.\n",
    "\n",
    "Define a function to replace ',' with ''.\n",
    "\n",
    "Use this function to replace the commas in 'Area' and 'Pop'.\n",
    "\n",
    "Submit your code and a final display of your table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alaska'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Courtesy of Jennifer Mead\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "state_data = {'State':['Alabama','Alaska','Arizona','Arkansas'],\n",
    "              'PostCode':['AL','AK','AZ','AR'],\n",
    "              'Area':['52,423','656,424','*','53,182'],\n",
    "              'Pop':['4,040,587','550,043','3,665,228','2,350,750']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 and 2\n",
    "state_df = pd.DataFrame(state_data, \n",
    "                        columns = ['State', 'PostCode', 'Area', 'Pop'])\n",
    "state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "state_df['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "state_df = state_df.replace('*','0')\n",
    "state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "def rid_commas(string_to_change):\n",
    "    return string_to_change.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "state_df['Pop'] = state_df['Pop'].map(rid_commas)\n",
    "state_df['Area'] = state_df['Area'].map(rid_commas)\n",
    "state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Exercise: Courtesy of Brad Coy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response type is: <class 'str'> \n",
      "\n",
      "The beginning of the response is: \n",
      " <!DOCTYPE html>\n",
      "<html lang=\"en-US\">\n",
      "<head>\n",
      "\t<!-- meta -->\n",
      "\t\t<meta charset=\"UTF-8\" />\n",
      "\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" />\n",
      "\t\t<!-- type -->\n",
      "\t\t\t<meta name=\"twitter:card\" content=\"summary\" />\n",
      "\t\t\t<meta property=\"og:type\" content=\"article\"/>\n",
      "\t\t<!-- site -->\n",
      "\t\t\t<meta name=\"twitter:site\" content=\"@SyracuseUNews\" />\n",
      "\t\t\t<meta property=\"og:site_name\" content=\"SU News\"/>\n",
      "\t\t<!-- title -->\n",
      "\t\t\t<meta name=\"twitter:title\" content=\"Light Work Awarded $100,0\n"
     ]
    }
   ],
   "source": [
    "# Obtain HTML data via urllib\n",
    "from urllib import request\n",
    "\n",
    "# Set the URL to scrape\n",
    "syrurl = \"https://news.syr.edu/blog/2019/07/24/light-work-awarded-100000-grant-from-the-andy-warhol-foundation-for-the-visual-arts/\"\n",
    "\n",
    "## Open, read, and decode the URL\n",
    "response = request.urlopen(syrurl).read().decode('utf8')\n",
    "\n",
    "# Check the type of the response variable\n",
    "print('The response type is:', type(response), '\\n')\n",
    "\n",
    "# Print the first 500 characters of the response\n",
    "print('The beginning of the response is:', '\\n', response[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new object type is: <class 'bs4.BeautifulSoup'> \n",
      "\n",
      "The title of the webpage is: Light Work Awarded $100,000 Grant from the Andy Warhol Foundation for the Visual Arts – Syracuse University News \n",
      "\n",
      "The first ten tags are: [<a class=\"skip-link screen-reader-text\" href=\"#entry-title\">Skip to main content</a>, <a href=\"https://news.syr.edu/\" title=\"Home\">Home</a>, <a href=\"https://news.syr.edu/about/\" title=\"About\">About</a>, <a href=\"https://news.syr.edu/faculty-experts/\" title=\"Faculty Experts\">Faculty Experts</a>, <a href=\"https://news.syr.edu/for-the-media/\" title=\"For The Media\">For The Media</a>, <a href=\"https://news.syr.edu/videos/\" title=\"Videos\">Videos</a>, <a href=\"https://news.syr.edu/topics/\" title=\"Topics\">Topics</a>, <a href=\"https://news.syr.edu/topics/alumni/\" title=\"Alumni\">Alumni</a>, <a href=\"https://news.syr.edu/topics/events/\">Events</a>, <a href=\"https://news.syr.edu/topics/faculty/\" title=\"Faculty\">Faculty</a>]\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML response via beautiful soup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the response variable\n",
    "parsed = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "# Check the type of the parsed variable\n",
    "print('The new object type is:', type(parsed), '\\n')\n",
    "\n",
    "# Title of the webpage\n",
    "print('The title of the webpage is:', parsed.title.get_text(), '\\n')\n",
    "\n",
    "# Print the first 10 tags\n",
    "print('The first ten tags are:', parsed.find_all('a')[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Exercise Courtesy of Amelia Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<!--[if IE 8]>       <html lang=\"en\" xml:lang=\"en\" class=\"no-js lt-ie9 site-wralsportsfan sports\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!--> <html lang=\"en\" xml:lang=\"en\" class=\"no-js site-wralsportsfan sports\"> <!--<![endif]-->\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>After Super Bowl win, Chiefs already eyeing repeat next year :: WRALSportsFan.com</title>\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    \n",
      "    \n",
      "<link rel=\"preconnect\" href=\"//fonts.googl\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb  3 20:41:18 2020\n",
    "\n",
    "@author: MrAndMrsKeith\n",
    "\"\"\"\n",
    "\n",
    "from urllib import request\n",
    "superbowlurl = \"https://www.wralsportsfan.com/after-super-bowl-win-chiefs-already-eyeing-repeat-next-year/18927591/\"\n",
    "# response = request.urlopen(superbowlurl)\n",
    "# print(type(response))\n",
    "\n",
    "# #If we just read the response, we get a sequence of bytes, so instead we decode it to convert it to a Python string.\n",
    "# html = response.read().decode('utf8')\n",
    "# print(type(html))\n",
    "\n",
    "html = request.urlopen(superbowlurl).read().decode('utf8')\n",
    "\n",
    "print(html[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup\n",
    "The Python package BeautifulSoup will parse the HTML document to find its structure, fixing any non-well-formed tag structure as best it can.\n",
    "http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "[An alternate package sometimes used is lxml.]\n",
    "The typical use is to use the BeautifulSoup parser on an HTML document to get a soup object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<title>After Super Bowl win, Chiefs already eyeing repeat next year :: WRALSportsFan.com</title>\n",
      "<class 'bs4.element.Tag'>\n",
      "title\n",
      "After Super Bowl win, Chiefs already eyeing repeat next year :: WRALSportsFan.com\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "htmlsoup = BeautifulSoup(html, 'html.parser')\n",
    "print(type(htmlsoup))\n",
    "\n",
    "#A BeautifulSoup object corresponds to a tag. Every tag has a name, (possibly) some attributes, a value, and (possibly) some children. When you have a tag, you can get information about that as a node in the tree structure generated by the tags of the document. You can then navigate anything below that tag in the tree, either by looking for specific tags or by following the children.\n",
    "#So every tag and tag structure can be found from the object that we obtained from the parser. If you give the name of a tag, it will find the first instance of that tag.\n",
    "firsttitle = htmlsoup.title\n",
    "print(firsttitle)\n",
    "print(type(firsttitle))\n",
    "print(firsttitle.name)\n",
    "#Use the get_text() function to get the actual tag content:\n",
    "print(firsttitle.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Anchor tags\n",
    "\n",
    "We can also use the find_all() function to return a ResultSet of all the instances of that tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "612\n",
      "[<a class=\"skip-link\" href=\"#g-wrap-main\">skip to main content</a>, <a class=\"go-back\" href=\"https://www.wral.com/\">\n",
      "<span class=\"icon icon-ico-arrow-l\"></span>\n",
      "<span class=\"go-back-text\">WRAL.com</span>\n",
      "</a>, <a href=\"https://www.milb.com/durham\">Durham Bulls</a>, <a href=\"https://www.wralsportsfan.com/sportsradio/\">Sports Radio</a>, <a href=\"https://www.wralsportsfan.com/espntriangle/asset_gallery/14766290/\">Podcasts</a>, <a class=\"nav-sign-in\" href=\"https://www.wral.com/rs/page/2173159/?forwardto=https%3A%2F%2Fwww.wralsportsfan.com%2Fafter-super-bowl-win-chiefs-already-eyeing-repeat-next-year%2F18927591%2F\">Sign In<span class=\"dropdown-carat\"></span></a>, <a class=\"reset\" href=\"/rs/page/2173159/?s=password_recovery\">Forgot your password?</a>, <a href=\"https://www.wral.com/rs/page/2173159/?s=registration\">Register here.</a>]\n",
      "['#g-wrap-main', 'https://www.wral.com/', 'https://www.milb.com/durham', 'https://www.wralsportsfan.com/sportsradio/', 'https://www.wralsportsfan.com/espntriangle/asset_gallery/14766290/', 'https://www.wral.com/rs/page/2173159/?forwardto=https%3A%2F%2Fwww.wralsportsfan.com%2Fafter-super-bowl-win-chiefs-already-eyeing-repeat-next-year%2F18927591%2F', '/rs/page/2173159/?s=password_recovery', 'https://www.wral.com/rs/page/2173159/?s=registration', '/', '/voices/']\n",
      "209\n",
      "['https://www.wral.com/', 'https://www.milb.com/durham', 'https://www.wralsportsfan.com/sportsradio/', 'https://www.wralsportsfan.com/espntriangle/asset_gallery/14766290/', 'https://www.wral.com/rs/page/2173159/?forwardto=https%3A%2F%2Fwww.wralsportsfan.com%2Fafter-super-bowl-win-chiefs-already-eyeing-repeat-next-year%2F18927591%2F', 'https://www.wral.com/rs/page/2173159/?s=registration', 'http://www.highschoolot.com/content/blog/3274743/', 'https://www.highschoolot.com/highschoolot-honors/17504324/', 'https://www.wral.com/content/creative_services/promos/clickthru?oaparams=2__bannerid=1282__zoneid=1__cb=3ea43bafd8__oadest=https%3A%2F%2Fwww.nbc.com%2Flive', 'https://www.highschoolot.com/highschoolot-honors/17504324/']\n"
     ]
    }
   ],
   "source": [
    "anchors = htmlsoup.find_all('a')\n",
    "print(type(anchors))\n",
    "print(len(anchors))\n",
    "\n",
    "print(anchors[:8])\n",
    "\n",
    "#For each anchor, â€˜aâ€™ tag, we use the â€˜hrefâ€™ attribute to get the actual anchor part, where I converted the result to an actual string:\n",
    "links = [str(link.get('href')) for link in htmlsoup.find_all('a')]\n",
    "print(links[ :10])\n",
    "\n",
    "outlinks = [link for link in links if link.startswith('http')]\n",
    "print(len(outlinks))\n",
    "print(outlinks[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
